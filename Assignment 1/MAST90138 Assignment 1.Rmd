---
title: "MAST90138 Assignment 1"
author: "Haonan Zhong 867492"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Question 1a

For the matrix $\Sigma$ to be a covariance matrix, $\Sigma$ needs to be positive semi-definite and symmetric. In order for $\Sigma$ to be a symmetric matrix, $a$ must be equals to 2. Therefore, we have $$\Sigma=\Sigma^T= \begin{bmatrix} 1&2 \\ 2&b \\ \end{bmatrix}$$ 

And given that $\Sigma$ is positive semi-definite if $X^T\Sigma X \geqslant0$ for all $X$ $\neq$ 0, hence we need to identify values of $\mathit{b}$ that makes $\Sigma$ a positive semi-definite matrix.
Let $X = \begin{bmatrix} x_1 \\ x_2 \\ \end{bmatrix}$
$$
\begin{aligned}
X^T\Sigma X &= \begin{bmatrix} x_1&x_2 \\ \end{bmatrix}\begin{bmatrix} 1&2 \\ 2&b \\ \end{bmatrix}\begin{bmatrix} x_1 \\ x_2 \\ \end{bmatrix} \\
&= x_{1}^2+4x_1x_2+bx_2^2 \\
&= x_{1}^2+4x_1x_2+4x_2^2+bx_2^2-4x_2^2\\
&= (x_1+2x_2)^2+(b-4)x_2^2 \geqslant0
\end{aligned}
$$
From the above equation, we can see that
$$
\begin{aligned}
(x_1+2x_2)^2 &\geqslant 0\\
(b-4)x_2^2 &\geqslant 0 \\
\therefore b\geqslant4
\end{aligned}
$$
Therefore, $\Sigma$ is positive semi-definite when $b \geqslant 4$. Hence, $\Sigma$ is a covariance matrix when $a=2$ and $b \geqslant4$.

### Question 1b
To find the eigenvalues of $\Sigma$, we have
$$det(\Sigma-\lambda I) = det(\begin{bmatrix} 13&-4 \\ -4&7 \\ \end{bmatrix} - \begin{bmatrix} \lambda&0 \\ 0&\lambda \\ \end{bmatrix}) = |\begin{bmatrix} 13-\lambda&-4 \\ -4&7-\lambda \\ \end{bmatrix}|=0$$
Therefore, we have $(13-\lambda)(7-\lambda)-16 = 0$
$$\therefore \lambda^2 - 20\lambda+75=0 $$
$$(\lambda-5)(\lambda-15)=0 $$
$$\therefore \lambda = 5, \; \lambda = 15$$
Thus, the eigenvalues of $\Sigma$ is 5 and 15, respectively. Next, we will compute the corresponding othonormal eigenvectors.

When $\lambda = 15$,
$$(\begin{bmatrix} 13&-4 \\ -4&7 \\ \end{bmatrix} - \begin{bmatrix} 15&0 \\ 0&15 \\ \end{bmatrix}) \times v_1 = 0 $$
$$\begin{bmatrix} -2&-4 \\ -4&-8 \\ \end{bmatrix} \times \begin{bmatrix} v_{11} \\ v_{12} \\ \end{bmatrix} =0$$
$$-2v_{11}-4v_{12} = 0$$
$$-4v_{11}-8v_{12}=0$$
Solving the above equations we have $v_{11} = -2$ and $v_{12} = 1$, and the orthonormal eigenvector $v_1$ is,
$$\frac{1}{\sqrt{(-2)^2+1^2}}\begin{bmatrix} -2 \\ 1 \end{bmatrix} = \begin{bmatrix} \frac{-2}{\sqrt{5}} \\ \frac{1}{\sqrt{5}} \end{bmatrix}$$
When $\lambda = 5$,
$$(\begin{bmatrix} 13&-4 \\ -4&7 \\ \end{bmatrix} - \begin{bmatrix} 5&0 \\ 0&5 \\ \end{bmatrix}) \times v_2 = 0 $$
$$\begin{bmatrix} 8&-4 \\ -4&2 \\ \end{bmatrix} \times \begin{bmatrix} v_{21} \\ v_{22} \\ \end{bmatrix} =0$$
$$8v_{21} - 4v_{22} = 0$$
$$-4v_{21}+2v_{22}=0$$
Solving the above equations we have $v_{21} = 1$ and $v_{22} = 2$, and the orthonormal eigenvector $v_2$ is,
$$\frac{1}{\sqrt{1^2+2^2}}\begin{bmatrix} 1 \\ 2 \end{bmatrix} = \begin{bmatrix} \frac{1}{\sqrt{5}} \\ \frac{2}{\sqrt{5}} \end{bmatrix}$$
Therefore, $$\Gamma = \begin{bmatrix} \frac{-2}{\sqrt{5}}&&\frac{1}{\sqrt{5}}\\ \frac{1}{\sqrt{5}}&&\frac{2}{\sqrt{5}} \\ \end{bmatrix} \;and\; \Lambda = \begin{bmatrix} 15&&0\\ 0&&5 \\ \end{bmatrix}$$

```{r}
Lambda <- diag(c(15, 5))
Gamma <- matrix(c(-2/sqrt(5), 1/sqrt(5), 1/sqrt(5), 2/sqrt(5)), 2, 2)
(Sigma <- Gamma %*% Lambda %*% t(Gamma))
```
As we can see from the R output above, our calculations are indeed correct!

### Question 1c
```{r}
X <- read.csv("Wheat data.txt", sep = "", header = F)
# printing wheat variety vector
(wheat_variety <- X[, 8])
X <- as.matrix(X[, -c(8)])
# printing the dimension of X
dim(X)
# printing the data matrix X
X
```

### Question 1d
```{r}
# Calculating the unbiased sample covariance matrix
(S <- cov(X))
# Computing the eigenvalues and eigenvectors of S
eigenval <- eigen(S)$values
eigenvec <- eigen(S)$vectors
# Constructing Lambda and Gamma
Lambda <- diag(eigenval)
Gamma <- as.matrix(eigenvec)
# Computing the spectral decomposition of S
Gamma %*% Lambda %*% t(Gamma)
```
As we can see from the result above, we indeed have $\Gamma \Lambda \Gamma^T = S$, where $\Lambda$ and $\Gamma$ is:
```{r}
Lambda
Gamma
```
\newpage

### Question 2a
```{r}
suppressMessages(library(ICSNP))
data(pulmonary)
plot(pulmonary)
```
As shown in scatter plot above, we can see that FVC and FEV might share a linear relationship.
\newpage

### Question 2b
```{r}
maha_dist <- mahalanobis(x = pulmonary, center = colMeans(pulmonary), cov(pulmonary))
normal <- qnorm(pchisq(maha_dist, 3))
qqnorm(normal)
qqline(normal, col = 'red')
```
As we can see from the plot above, the points are relatively linear and roughly fall along a straight line, we can say that the mahalanobis distance roughly follows a $\chi^2$ distribution with df = 3, therefore, we may conclude that the data might come from a multivariate normal distribution.

### Question 2c
```{r}
HotellingsT2(X = pulmonary, mu = c(0, 0, 0))
```
As the result above stated, the p-value is 0.05123, which is slight greater than the significance level of 0.05, hence we do not reject the null hypothesis, where the means of the three variables are all zero.
```{r}
# Obtain the degrees of freedom
n <- dim(pulmonary)[1]
p <- dim(pulmonary)[2]
sample_mean <- matrix(colMeans(pulmonary))
mu <- matrix(c(0, 0, 0))
(T_2 <- n * t(sample_mean - mu) %*% solve(cov(pulmonary)) %*% (sample_mean - mu))
```

```{r}
(F_stat <- (n - p)/((n - 1) * p) * T_2)
```
```{r}
pf(F_stat, p, n - p, lower.tail = FALSE)
```
Using the equivalence of Hotelling's $T^2$ statistics and $F_{p, n-p}$ distribution, the p-value of the test statistic is equal to 0.05123, which is the same as the p-value calculated using the R function above. And since the p-value slight greater than the significance level of 0.05, hence we do not reject the null hypothesis, where the means of the three variables are all zero.
